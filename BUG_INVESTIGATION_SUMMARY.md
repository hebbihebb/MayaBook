# Bug Investigation Summary - First Paragraph Silent Issue

## Problem Statement
User reports that when using the GUI with a test EPUB file containing 2 paragraphs, only the second paragraph is audible in the final audio/video output. The first paragraph appears to be missing.

## Investigation Timeline

### Test 1: CLI Testing
**Result:** ✅ WORKING
- Tested with 2-paragraph text
- Both paragraphs rendered correctly
- Output file: `output/debug_test2.wav` (29.57s)
- All 30 seconds audible (RMS check passed)

### Test 2: GUI Output Analysis
**Result:** ⚠️ ANOMALY DETECTED
- Analyzed `output/sample.wav` generated by GUI (from log 073803)
- File duration: 34.55s
- Expected: 12.20s (chunk 0) + 0.25s (gap) + 22.10s (chunk 1) = 34.55s ✅
- **All 35 seconds show good RMS values** (no silent segments detected)
- **But user reports only hearing second paragraph**

### Test 3: Concatenation Verification
**Result:** ✅ CORRECT
- Logs show both chunks concatenated in correct order:
  - Chunk 0: 292,864 samples (12.20s), RMS=0.122477
  - Gap: 6,000 samples (0.25s)
  - Chunk 1: 530,432 samples (22.10s), RMS=0.116146
  - **Total: 829,296 samples (34.55s)** ✅ Math checks out!

### Test 4: Chunk Text Verification
**Result:** ✅ CORRECT - Different text in each chunk
- Chunk 0 text: "I thought you'd be at the station by now," Mara said...
- Chunk 1 text: "<whisper> But when I saw you waiting, I realised..."
- **Chunks have different text** ✅

### Test 5: Audio Content Comparison
**Result:** ✅ DIFFERENT - Chunks are not identical
- Chunk 0 stats: std=0.122477, min=-0.557, max=0.731
- Chunk 1 stats: std=0.116146, min=-0.635, max=0.611
- Correlation between first 1000 samples: 0.334 (low, indicating different content)
- **Chunks contain different audio** ✅

## Current Status

### What We Know FOR CERTAIN:
1. ✅ Text extraction works (2 different paragraphs extracted)
2. ✅ Text chunking works (2 chunks created with different text)
3. ✅ TTS synthesis works (both chunks generate audio with good RMS)
4. ✅ Audio concatenation works (correct order, correct duration)
5. ✅ Both chunks have audio content (no silent segments)
6. ✅ Chunks contain different audio (not duplicates)

### What Remains UNEXPLAINED:
- ❓ User reports only hearing the second paragraph
- ❓ File duration matches expected (34.55s), but user says first ~13s is not the first paragraph
- ❓ RMS values are good throughout, no detection of silence

## Hypotheses

### Hypothesis 1: TTS Model Generating Wrong Content
The TTS model might be:
- Ignoring the input text for the first chunk
- Generating unintelligible speech that has good RMS but isn't understandable
- Generating similar-sounding speech for both chunks despite different input text

**Test:** Need user to describe what they hear in first 13 seconds

### Hypothesis 2: Playback/Caching Issue
- Media player showing cached older version
- MP4 encoding issue (while WAV is correct)
- System audio routing issue

**Test:** User should try different media players, delete and regenerate files

### Hypothesis 3: Perception Issue
- First chunk audio is present but unclear/garbled
- Speaking style makes it hard to understand
- Volume/pacing differences between chunks

**Test:** User should listen very carefully to first 13 seconds with headphones

## Diagnostic Changes Made

### 1. Enhanced Logging in `core/audio_combine.py`
- Shows shape, duration, and RMS of each chunk during concatenation
- Shows final combined audio statistics
- Helps verify correct file handling

### 2. Created `diagnose_audio.py`
- Analyzes audio files second-by-second
- Detects silent segments (RMS < 0.001)
- Provides detailed audio statistics

### 3. Added Text Logging in `core/tts_maya1_local.py`
- Logs the first 100 characters of text being synthesized
- Shows text length
- Helps verify correct text is being sent to TTS

## Next Steps

1. **User Action Required:** Run GUI again and check new log file for "Synthesizing text" lines to see exactly what text each chunk receives

2. **User Action Required:** Describe what you hear in:
   - First 5 seconds of `output/sample.wav`
   - Seconds 5-10
   - Seconds 10-15
   - Seconds 15-20

3. **Possible Solution:** If TTS model is generating wrong content, we may need to:
   - Adjust temperature/top-p parameters
   - Add more context to prompts
   - Try different voice descriptions
   - Check if model is working correctly

## Files Modified
- `core/audio_combine.py` - Added diagnostic logging
- `core/tts_maya1_local.py` - Added text synthesis logging
- `diagnose_audio.py` - New diagnostic tool (created)

## Conclusion
The audio processing pipeline is technically correct. Both paragraphs are being extracted, chunked, synthesized, and concatenated properly. The issue appears to be either:
- TTS model not respecting input text for first chunk
- User playback/perception issue
- Some unknown factor affecting audio quality/content

**More testing needed to identify root cause.**
