## MayaBook Dev Log — 2025‑11‑13

### Environment & Tooling
- Confirmed PyTorch CUDA availability was `False` initially; rebuilt `llama-cpp-python` 0.3.16 from source with `GGML_CUDA=on`, enabling RTX 4060 Laptop GPU offload.
- Verified CUDA init logs (`ggml_cuda_init: found 1 CUDA devices`) and ran the CLI pipeline to ensure the GGUF model executes on GPU.
- FFmpeg was present but `assets/cover.jpg` was missing in several runs, which explained MP4 export failures.

### Investigations
- HuggingFace safetensor path: left as-is for Linux testing later, but captured logs showing 4-bit CPU execution plus long load times.
- GUI tests showed only the second paragraph audible. Logs revealed both chunks were generated, but temp WAV inspection (`tmpybgcbogq.wav`) exposed ~9 s of near-zero audio for chunk 1. This coincided with the new CUDA build: llama.cpp no longer returned `completion_tokens`, forcing a lossy “re-tokenize text” fallback that occasionally produced silent SNAC codes.
- Measured RMS/first-nonzero samples for multiple temp WAVs to confirm the silence issue and compared against healthy runs.

### Fixes
- Updated `core/tts_maya1_local.py`:
  - Added deterministic seeding via CRC32 of text + voice, passed through llama.cpp’s `seed` parameter.
  - Introduced a helper to run generation + SNAC decode, returning numpy audio.
  - Added an RMS guard (`MIN_AUDIO_RMS = 1e-3`) with up to three retries using incremented seeds; logs now show seed/RMS info.
  - Imported `numpy`/`zlib` for RMS math and seed hashing.
- After the patch, new chunk WAVs (`tmpztar897g.wav`, `tmpw3zitmu7.wav`) had immediate non-zero content (RMS ≈ 0.097 / 0.105) and no long silence, so concatenated audio contains both paragraphs again.

### Remaining Items / Notes
- MP4 export still fails until a real cover image is added at `assets/cover.jpg` or via GUI selection.
- HuggingFace safetensor path still runs on CPU; revisit on Linux with bitsandbytes GPU kernels.
- Consider persisting the RMS retry logic for the HF pipeline too once that path is active.
